{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time \n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from create_financial_database import get_credentials \n",
    "from SQLite_tools import query_stock_data, check_if_close_price_exists\n",
    "from ticker_loader import load_SPY_components\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "#import ImbalancedDatasetSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output :\n",
      "2.2.0+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1 \n",
      "\n",
      "Actual Output :\n",
      "2.2.0+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "CUDA: True cpu\n",
      "\n",
      "PyTorch Devices:  NVIDIA GeForce RTX 3060\n",
      "Using GPU:  True\n",
      "DEVICE:  cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected Output :\")\n",
    "print(\"2.2.0+cu121\")\n",
    "print(\"CUDA available: True\")\n",
    "print(\"CUDA version: 12.1 \\n\")\n",
    "print(\"Actual Output :\")\n",
    "print(torch.__version__)  \n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "print(\"CUDA:\", USE_CUDA, DEVICE)\n",
    "print(\"\")\n",
    "print(\"PyTorch Devices: \", torch.cuda.get_device_name(0))\n",
    "print(\"Using GPU: \", USE_CUDA)\n",
    "print(\"DEVICE: \", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instance_id': 2903577,\n",
       " 'ticker': 'ZTS',\n",
       " 'ticker_idx': 733,\n",
       " 'window': array([[ 0.12254116,  0.25601934, -0.84055526, -0.76457537, -0.02506234,\n",
       "         -0.02527723, -0.19047589, -0.19248162, -0.41871859, -0.32199907,\n",
       "         -0.20232042, -0.07964685,  0.14715067, -0.12516569,  1.59445815,\n",
       "         -0.52579677, -0.03342265,  0.26320189,  0.42490559,  0.35513859,\n",
       "          0.49803776,  0.50527383, -0.17948227, -0.14147084,  0.59037396,\n",
       "          0.24346065,  0.38853698, -0.60667225,  0.9887194 , -0.79836474,\n",
       "         -0.16296185,  0.56846405, -0.08391866,  0.65376341,  0.24796584,\n",
       "          0.19390044,  0.02787609,  0.11651947, -0.35853148,  0.18333564,\n",
       "          0.21109882, -0.21741926, -0.04909748, -0.03888687,  0.7661333 ,\n",
       "          0.91521042, -0.7180225 , -0.40299145, -0.24159425, -0.46659269,\n",
       "         -0.27657878, -0.67801973, -0.97433974,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.08131037,  0.36178744, -0.52987846,  0.25713182, -0.02506234,\n",
       "         -0.02527723, -0.19047589, -0.19248162, -0.41871859, -0.32199907,\n",
       "         -0.20232042, -0.07964685,  0.14715067, -0.12516569,  1.59445815,\n",
       "         -0.52579677, -0.03342265,  0.26320189,  0.42490559,  0.35513859,\n",
       "          0.49803776,  0.50527383, -0.17948227, -0.14147084,  0.59037396,\n",
       "          0.24346065,  0.11767241, -0.87614668,  0.84873692, -0.93733751,\n",
       "         -0.2261319 ,  0.45873128, -0.12343518,  0.56250883,  0.08964405,\n",
       "          0.09656631,  0.01613528,  0.09788466, -0.33091611,  0.17409097,\n",
       "          0.20488197, -0.22699568, -0.06419774, -0.05181686,  0.63828758,\n",
       "          0.81856815, -0.46343681, -0.23864729, -0.16212934, -0.25736672,\n",
       "         -0.27681369, -0.67446632, -0.97022445,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.38499662,  0.19489436, -0.75288444, -0.04205034, -0.02506234,\n",
       "         -0.02527723, -0.19047589, -0.19248162, -0.41871859, -0.32199907,\n",
       "         -0.20232042, -0.07964685,  0.14715067, -0.12516569,  1.59445815,\n",
       "         -0.52579677, -0.03342265,  0.26320189,  0.42490559,  0.35513859,\n",
       "          0.49803776,  0.50527383, -0.17948227, -0.14147084,  0.59037396,\n",
       "          0.24346065, -0.1532044 , -1.14561086,  0.70875479, -1.07631117,\n",
       "         -0.22108481,  0.47505358, -0.124876  ,  0.55110564,  0.07989775,\n",
       "          0.09193699,  0.00609487,  0.08139154, -0.30504179,  0.1663409 ,\n",
       "          0.19987174, -0.23595839, -0.06307008, -0.05084939,  0.64783877,\n",
       "          0.82578877, -0.48001501, -0.25101949, -0.03801478, -0.30879183,\n",
       "         -0.27677462, -0.67538444, -0.96999162,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.14596039,  0.35938982, -0.35392344,  0.21381569, -0.02506234,\n",
       "         -0.02527723, -0.19047589, -0.19248162, -0.41871859, -0.32199907,\n",
       "         -0.20232042, -0.07964685,  0.14715067, -0.12516569,  1.59445815,\n",
       "         -0.52579677, -0.03342265,  0.26320189,  0.42490559,  0.35513859,\n",
       "          0.49803776,  0.50527383, -0.17948227, -0.14147084,  0.59037396,\n",
       "          0.24346065, -0.42411412, -1.41506207,  0.56876069, -1.21528483,\n",
       "         -0.27724148,  0.39080693, -0.16469162,  0.48070912, -0.02981593,\n",
       "          0.01686252,  0.00630816,  0.06760034, -0.24826608,  0.16009247,\n",
       "          0.19377381, -0.23363358, -0.08383496, -0.06171043,  0.54046087,\n",
       "          0.74462092, -0.24528896, -0.10576302, -0.14169672, -0.29409296,\n",
       "         -0.27696889, -0.67814525, -0.97316645,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.35710687,  1.28948905,  0.12349449,  1.2129965 , -0.02506234,\n",
       "         -0.02527723, -0.19047589, -0.19248162, -0.41871859, -0.32199907,\n",
       "         -0.20232042, -0.07964685,  0.14715067, -0.12516569,  1.59445815,\n",
       "         -0.52579677, -0.03342265,  0.26320189,  0.42490559,  0.35513859,\n",
       "          0.49803776,  0.50527383, -0.17948227, -0.14147084,  0.59037396,\n",
       "          0.24346065, -0.69502027,  1.27926758,  0.42877058, -1.35425909,\n",
       "         -0.42096178, -0.10890116, -0.32560371,  0.15990771, -0.50177983,\n",
       "         -0.31720487,  0.04791513,  0.06303479, -0.05993044,  0.16077747,\n",
       "          0.18458703, -0.18816282, -0.11639627, -0.11700522, -0.00614921,\n",
       "          0.33144346,  0.70467   ,  0.56693569,  0.4197044 , -0.09283191,\n",
       "         -0.27803937, -0.68122752, -0.97688762,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ]]),\n",
       " 'target': -2,\n",
       " 'start_date': '2024-01-31',\n",
       " 'end_date': '2024-02-06',\n",
       " 'prediction_date': '2024-02-06',\n",
       " 'window_dates': array(['2024-01-31', '2024-02-01', '2024-02-02', '2024-02-05',\n",
       "        '2024-02-06'], dtype=object)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the directory containing the chunks\n",
    "# CHUNK_DATA_DIR = \"../Data/Networks_chunks/window_size_10\"\n",
    "# CHUNK_DATA_DIR = \"../Data/Networks_chunks/window_size_10\"\n",
    "# CHUNK_DATA_DIR = \"../Data/Networks_chunks/window_size_3\"\n",
    "WINDOW_SIZE = 5\n",
    "data_file_path = f\"../Data/LSTM_Data/lstm_windowed_data_{WINDOW_SIZE}.pkl\"\n",
    "# data_file_path = \"../Data/LSTM_Data/lstm_windowed_data_{WINDOW_SIZE}.pkl\"\n",
    "\n",
    "\n",
    "def load_windowed_data(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        lstm_dataset = pickle.load(f)\n",
    "    return lstm_dataset\n",
    "\n",
    "\n",
    "total_lstm_dataset = load_windowed_data(data_file_path)\n",
    "total_lstm_dataset[-100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance_pred_date:  2018-12-07\n",
      "instance_ticker: A\n",
      "target_instance Shape: torch.Size([])\n",
      "target_instance: tensor(-1.)\n",
      "target_instance type: <class 'torch.Tensor'>\n",
      "window_data_instace Shape: torch.Size([5, 70])\n",
      "window_data_instace: tensor([[ 0.0117,  0.5581, -0.1444,  0.3993,  0.0072,  0.0298, -0.2075, -0.0099,\n",
      "          0.1391,  0.0674,  0.1739,  0.3312, -0.5357, -0.7263, -0.3017, -0.9592,\n",
      "         -0.1857,  0.0961,  0.3064,  0.2900,  0.3800,  0.4602, -0.2640, -0.3817,\n",
      "          0.5314, -0.2563, -0.6953,  1.2823,  0.4326,  1.2880, -0.1897, -1.1853,\n",
      "         -0.3664, -0.7594, -0.8016, -0.7424,  0.3298,  0.1184,  0.8792,  0.0798,\n",
      "          0.0100,  0.2867, -0.1009, -0.1249, -1.5258, -0.8229,  1.4637,  1.1086,\n",
      "          1.3019,  0.8082, -0.2891, -0.6748, -0.6760,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5011,  1.2787,  0.4266,  1.2148,  0.0072,  0.0298, -0.2075, -0.0099,\n",
      "          0.1391,  0.0674,  0.1739,  0.3312, -0.5357, -0.7263, -0.3017, -0.9592,\n",
      "         -0.1857,  0.0961,  0.3064,  0.2900,  0.3800,  0.4602, -0.2640, -0.3817,\n",
      "          0.5314, -0.2563, -0.9665,  1.2822,  0.2923,  1.2880, -0.2762, -1.4940,\n",
      "         -0.4332, -1.1057, -1.1139, -0.9827,  0.4051,  0.1685,  0.9847,  0.1056,\n",
      "          0.0185,  0.3543, -0.1055, -0.1288, -2.0185, -1.1964,  1.8302,  1.4881,\n",
      "          1.6662,  1.0044, -0.2907, -0.6746, -0.6835,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0050,  0.2091, -1.0730, -0.9285,  0.0072,  0.0298, -0.2075, -0.0099,\n",
      "          0.1391,  0.0674,  0.1739,  0.3312, -0.5357, -0.7263, -0.3017, -0.9592,\n",
      "         -0.1857,  0.0961,  0.3064,  0.2900,  0.3800,  0.4602, -0.2640, -0.3817,\n",
      "          0.5314, -0.2563, -1.2377,  1.2821,  0.1521,  1.2880, -0.1612, -0.6551,\n",
      "         -0.2661, -0.8959, -0.5642, -0.6545,  0.4487,  0.2231,  0.9403,  0.1255,\n",
      "          0.0275,  0.3947, -0.0517, -0.0837, -1.0095, -0.9153,  1.0553,  0.9712,\n",
      "          1.8489,  0.7820, -0.2894, -0.6832, -0.6917,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.9240, -0.5383, -1.6110, -0.5488,  0.0072,  0.0298, -0.2075, -0.0099,\n",
      "          0.1391,  0.0674,  0.1739,  0.3312, -0.5357, -0.7263, -0.3017, -0.9592,\n",
      "         -0.1857,  0.0961,  0.3064,  0.2900,  0.3800,  0.4602, -0.2640, -0.3817,\n",
      "          0.5314, -0.2563, -1.2376,  1.0124,  0.0118,  1.1488, -0.0515, -0.3022,\n",
      "         -0.1644, -0.7500, -0.2560, -0.4533,  0.4599,  0.2692,  0.7970,  0.1387,\n",
      "          0.0370,  0.4053, -0.0248, -0.0611, -0.2423, -0.7495,  0.6699,  0.6995,\n",
      "          0.6819,  0.6443, -0.2887, -0.6815, -0.6843,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.1274,  0.0762, -1.2311, -0.9096,  0.0072,  0.0298, -0.2075, -0.0099,\n",
      "          0.1391,  0.0674,  0.1739,  0.3312, -0.5357, -0.7263, -0.3017, -0.9592,\n",
      "         -0.1857,  0.0961,  0.3064,  0.2900,  0.3800,  0.4602, -0.2640, -0.3817,\n",
      "          0.5314, -0.2563, -0.9665,  0.7428, -0.1285,  1.0096,  0.1014,  0.1801,\n",
      "         -0.0308, -0.5285,  0.1469, -0.1691,  0.4393,  0.3056,  0.5612,  0.1447,\n",
      "          0.0463,  0.3867,  0.0216, -0.0223,  0.1628, -0.4638,  0.1030,  0.2794,\n",
      "          0.3576,  0.1319, -0.2875, -0.6847, -0.6851,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "window_data_instace type: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "class LSTMDataset:\n",
    "    \"\"\"\n",
    "    PyTorch Dataset class for creating train, validation, and test splits from windowed data.\n",
    "\n",
    "    Args:\n",
    "        windowed_data (list): List of dictionaries, each containing a window and metadata.\n",
    "        val_date (str): The cutoff date for the validation set. Instances with `start_date` >= `val_date` go into the validation set.\n",
    "        test_date (str): The cutoff date for the test set. Instances with `start_date` >= `test_date` go into the test set.\n",
    "    \"\"\"\n",
    "    def __init__(self, windowed_data, val_date, test_date):\n",
    "        self.windowed_data = windowed_data\n",
    "        self.val_date = val_date\n",
    "        self.test_date = test_date\n",
    "\n",
    "    def _filter_split(self, split):\n",
    "        \"\"\"\n",
    "        Filters the dataset based on the split and dates.\n",
    "\n",
    "        Args:\n",
    "            split (str): The split type (\"train\", \"val\", or \"test\").\n",
    "\n",
    "        Returns:\n",
    "            list: The filtered dataset for the specified split.\n",
    "        \"\"\"\n",
    "        if split == \"train\":\n",
    "            return [d for d in self.windowed_data if d['start_date'] < self.val_date]\n",
    "        elif split == \"val\":\n",
    "            return [d for d in self.windowed_data if self.val_date <= d['start_date'] < self.test_date]\n",
    "        elif split == \"test\":\n",
    "            return [d for d in self.windowed_data if d['start_date'] >= self.test_date]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid split type. Choose from 'train', 'val', or 'test'.\")\n",
    "\n",
    "    def get_datasets(self):\n",
    "        \"\"\"\n",
    "        Returns the train, validation, and test datasets.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Three PyTorch datasets for train, val, and test splits.\n",
    "        \"\"\"\n",
    "        train_data = self._filter_split(\"train\")\n",
    "        val_data = self._filter_split(\"val\")\n",
    "        test_data = self._filter_split(\"test\")\n",
    "\n",
    "        return (\n",
    "            SingleSplitDataset(train_data),\n",
    "            SingleSplitDataset(val_data),\n",
    "            SingleSplitDataset(test_data)\n",
    "        )\n",
    "\n",
    "\n",
    "class SingleSplitDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for a single split (train, val, or test).\n",
    "\n",
    "    Args:\n",
    "        split_data (list): List of dictionaries containing the split data.\n",
    "    \"\"\"\n",
    "    def __init__(self, split_data):\n",
    "        self.data = split_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        instance = self.data[idx]\n",
    "        window = torch.tensor(instance['window'], dtype=torch.float32) \n",
    "        target = torch.tensor(instance['target'], dtype=torch.float32)   # converting int to float to define the task as a regression problem\n",
    "        prediction_date = instance['prediction_date']  \n",
    "        ticker = instance['ticker']  \n",
    "        return window, target, prediction_date, ticker\n",
    "\n",
    "\n",
    "# I messed up the dates a bit, but it's close enough\n",
    "val_date = \"2016-11-30\"\n",
    "test_date =\"2018-11-30\"\n",
    "\n",
    "lstm_dataset = LSTMDataset(total_lstm_dataset, val_date, test_date)\n",
    "train_dataset, val_dataset, test_dataset = lstm_dataset.get_datasets()\n",
    "\n",
    "\n",
    "for window_data_instace, target_instance, instance_pred_date, instance_ticker in test_dataset:\n",
    "    print(\"instance_pred_date: \", instance_pred_date)\n",
    "    print(\"instance_ticker:\", instance_ticker)\n",
    "    print(\"target_instance Shape:\", target_instance.shape)\n",
    "    print(\"target_instance:\", target_instance)\n",
    "    print(\"target_instance type:\", type(target_instance))\n",
    "    print(\"window_data_instace Shape:\", window_data_instace.shape)\n",
    "    print(\"window_data_instace:\", window_data_instace)\n",
    "    print(\"window_data_instace type:\", type(window_data_instace))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Dates: ('1999-10-08', '1996-06-13', '2000-06-08', '2001-12-27', '2006-12-14', '2003-11-26', '2007-10-26', '2014-07-23', '2005-02-10', '2006-02-27', '2007-08-07', '2004-01-20', '2009-06-29', '2005-10-24', '2014-12-12', '2004-09-14')\n",
      "Batch Windows Shape: torch.Size([16, 5, 70])\n",
      "Batch Targets Shape: torch.Size([16])\n",
      "Batch Targets: tensor([-2., -2.,  0., -1.,  0.,  1.,  1.,  0.,  0., -1., -2.,  0., -2.,  1.,\n",
      "         0.,  0.])\n",
      "Batch Tickers Shape: 16\n",
      "Batch Tickers: ('IFF', 'BAC', 'LEG', 'WMB', 'FMC', 'SEE', 'CNP', 'EBAY', 'PX', 'DOV', 'FE', 'ETR', 'CHRW', 'PSA', 'RAI', 'CCI')\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for batch_window, batch_targets, batch_dates, batch_ticker in train_loader:\n",
    "    print(\"Batch Dates:\", batch_dates)  \n",
    "    print(\"Batch Windows Shape:\", batch_window.shape)  \n",
    "    print(\"Batch Targets Shape:\", batch_targets.shape)  \n",
    "    print(\"Batch Targets:\", batch_targets) \n",
    "    print(\"Batch Tickers Shape:\", len(batch_ticker))  \n",
    "    print(\"Batch Tickers:\", batch_ticker)  \n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size (int): Number of features per time step (e.g., 70 for this dataset).\n",
    "            hidden_size (int): Number of features in the hidden state.\n",
    "            num_layers (int): Number of stacked LSTM layers.\n",
    "            output_size (int): Size of the output (e.g., 1 for scalar regression).\n",
    "            dropout (float): Dropout probability for each connection between LSTM layers (0.0 for no dropout).\n",
    "        \"\"\"\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,      \n",
    "            hidden_size=hidden_size,     \n",
    "            num_layers=num_layers,       \n",
    "            batch_first=True,       \n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=dropout)  \n",
    "        self.fc = nn.Linear(hidden_size, output_size)  # Fully connected output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)  # Shape: (batch_size, sequence_length, hidden_size)\n",
    "        # Use the last time step's hidden state\n",
    "        last_hidden_state = lstm_out[:, -1, :]  # Shape: (batch_size, hidden_size)\n",
    "        # Apply dropout\n",
    "        last_hidden_state = self.dropout(last_hidden_state)\n",
    "        # Fully connected layer for output\n",
    "        output = self.fc(last_hidden_state)  \n",
    "        return output.squeeze()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device, save_pred = False):\n",
    "    \"\"\"\n",
    "    Evaluates the model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The LSTM model.\n",
    "        dataloader (DataLoader): DataLoader for the validation or test data.\n",
    "        criterion: Loss function.\n",
    "        device: Device to run the model on (\"cpu\" or \"cuda\").\n",
    "\n",
    "    Returns:\n",
    "        tuple: Average loss and predictions.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    tickers = []\n",
    "    with torch.no_grad():\n",
    "        for batch_windows, batch_targets, batch_dates, batch_tickers in dataloader:\n",
    "            batch_windows, batch_targets = batch_windows.to(device), batch_targets.to(device)\n",
    "            outputs = model(batch_windows)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            if save_pred:\n",
    "                predictions.extend(outputs.cpu().numpy())\n",
    "                targets.extend(batch_targets.cpu().numpy())\n",
    "                tickers.extend(batch_tickers)\n",
    "    if save_pred:\n",
    "        return total_loss / len(dataloader), predictions, targets, tickers\n",
    "    else:\n",
    "        return total_loss / len(dataloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedMSELoss(nn.Module):\n",
    "    def __init__(self, weights=None):\n",
    "        super(WeightedMSELoss, self).__init__()\n",
    "        self.weights = weights if weights else {-2: 1, -1: 1.0, 0: 1.0, 1: 1.0, 2: 1.0}\n",
    "        self.base_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        device = predictions.device\n",
    "        target_weights = torch.tensor([self.weights[int(target.item())] for target in targets], device=device)\n",
    "\n",
    "        mse_loss = self.base_loss(predictions, targets)\n",
    "        too_low_prediction_penalty = torch.zeros_like(predictions)\n",
    "        too_high_prediction_penalty = torch.zeros_like(predictions)\n",
    "\n",
    "        high_target_mask = (targets >= 1)\n",
    "        too_low_prediction_penalty[high_target_mask] = (predictions[high_target_mask] < targets[high_target_mask]).float() * 1.5\n",
    "        too_high_prediction_penalty[high_target_mask] = (predictions[high_target_mask] > targets[high_target_mask]).float() * 0.75\n",
    "\n",
    "        low_target_mask = (targets == -2)\n",
    "        too_low_prediction_penalty[low_target_mask] = (predictions[low_target_mask] > targets[low_target_mask]).float() * 1.5\n",
    "        too_high_prediction_penalty[low_target_mask] = (predictions[low_target_mask] < targets[low_target_mask]).float() * 0.75\n",
    "\n",
    "        penalties = 1 + too_low_prediction_penalty - too_high_prediction_penalty\n",
    "        weighted_loss = mse_loss * target_weights * penalties\n",
    "        return weighted_loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model at the last state from the checkpoint IF the notebook crashed or was stopped for some reason.\n",
    "\n",
    "# model_name = \"LSTM_4\"\n",
    "# checkpoint = torch.load(f\"../Data/Models/{model_name}.pt\")\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# # best_val_loss = checkpoint['best_val_loss']\n",
    "# model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Size: 70\n",
      "Hidden Size: 128\n",
      "Number of Layers: 3\n",
      "Output Size: 1\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(70, 128, num_layers=3, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Training Loop Parameters\n",
    "epochs = 500\n",
    "patience = 4\n",
    "force_epochs = 10\n",
    "stop_training = False\n",
    "\n",
    "learning_rate = 0.0000001\n",
    "gamma = 0.90 \n",
    "hidden_size = 128      \n",
    "drop_out_rate = 0.5\n",
    "weight_dict = {-2: 3.0, -1: 2.0, 0: 0.5, 1: 2.0, 2: 5.0} \n",
    "# weight_dict = {-2: 2.0, -1: 0.75, 0: 0.25 , 1: 3.0, 2: 8.0}\n",
    "num_layers = 3                             \n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "model_name = \"LSTM_4\"\n",
    "cur_patience = 0\n",
    "output_size = 1                                 # Single prediction per instance\n",
    "input_size = window_data_instace.shape[1]  #70  # Number of features per time step\n",
    "\n",
    "print(\"Input Size:\", input_size)\n",
    "print(\"Hidden Size:\", hidden_size)\n",
    "print(\"Number of Layers:\", num_layers)\n",
    "print(\"Output Size:\", output_size)\n",
    "\n",
    "# Model, criterion, optimizer\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size, drop_out_rate).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion            = WeightedMSELoss(weights=weight_dict)\n",
    "criterion_unweighted = WeightedMSELoss()\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m train_unweighted_losses, val_unweighted_losses \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Model Directory\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Data/Models/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      6\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Data/Models/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Early stopping model path\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_unweighted_losses, val_unweighted_losses = [], []\n",
    "\n",
    "# Model Directory\n",
    "if not os.path.exists(\"../Data/Models/\"):\n",
    "    os.makedirs(\"../Data/Models/\")\n",
    "\n",
    "# Early stopping model path\n",
    "model_path = f\"../Data/Models/{model_name}.pt\"\n",
    "model_train_start_time = time.time()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    total_unweighted_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as progress_bar:\n",
    "        for batch_windows, batch_targets, batch_dates, batch_tickers in train_loader:\n",
    "            batch_windows, batch_targets = batch_windows.to(DEVICE), batch_targets.to(DEVICE)\n",
    "            \n",
    "            # assert not torch.isnan(predictions).any(), \"Predictions contain NaN values!\"\n",
    "            # assert not torch.isinf(predictions).any(), \"Predictions contain Inf values!\"\n",
    "            # assert not torch.isnan(batch_targets).any(), \"Targets contain NaN values!\"\n",
    "            # assert not torch.isinf(batch_targets).any(), \"Targets contain Inf values!\"\n",
    "\n",
    "            # print(\"batch_windows shape:\", batch_windows.shape)\n",
    "            # print(\"batch_targets shape:\", batch_targets.shape)\n",
    "            # print(\"batch_targets:\", batch_targets)\n",
    "\n",
    "            predictions = model(batch_windows)\n",
    "            # predictions = torch.nan_to_num(predictions, nan=0.0)\n",
    "\n",
    "            # print(\"predictions shape:\", predictions.shape)\n",
    "            # print(\"predictions:\", predictions)\n",
    "\n",
    "\n",
    "            # These lines are here because I had a bug :)\n",
    "            if torch.isnan(predictions).any():\n",
    "                print(\"Some predictions are NaN, skipping batch.\")\n",
    "                continue\n",
    "            if torch.isnan(predictions).all():\n",
    "                print(\"All predictions are NaN, skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            loss = criterion(predictions, batch_targets)\n",
    "            unweighted_loss = nn.MSELoss()(predictions, batch_targets)  # Compute unweighted MSE for logging\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)  # Gradient clipping (not necessary for this model)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_unweighted_loss += unweighted_loss.item()\n",
    "\n",
    "            # I missed tensorflows progress bar, so I made my own which kind of works. D tier on visuals, B tier on effeciecy.\n",
    "            progress_bar.set_postfix({\"Training Loss\": f\"{total_loss / (progress_bar.n + 1):.4f}\"})  \n",
    "            progress_bar.update(1) \n",
    "\n",
    "\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_unweighted_loss = total_unweighted_loss / len(train_loader)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = evaluate(model, val_loader, criterion, DEVICE)\n",
    "    val_unweighted_loss = evaluate(model, val_loader, criterion_unweighted, DEVICE)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_unweighted_losses.append(train_unweighted_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_unweighted_losses.append(val_unweighted_loss)\n",
    "\n",
    "    # Early stopping / patience block\n",
    "    force_epochs -= 1\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        cur_patience = 0\n",
    "        torch.save({'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, model_path)\n",
    "    else:\n",
    "        if force_epochs <= 0:\n",
    "            cur_patience += 1\n",
    "            if cur_patience == patience:\n",
    "                print(f\"Early stopping: validation loss did not improve for {patience} epochs\")\n",
    "                break\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = learning_rate * (gamma ** epoch)\n",
    "\n",
    "    # Logging progress\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}   Current Learning Rate: {param_group['lr']}   Training Loss Weighted MSE: {train_loss:.4f}    \"\n",
    "          f\"Validation Loss Weighted MSE: {val_loss:.4f} | Unweighted MSE: {val_unweighted_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../Data/Results/LSTM_4_results.pkl\n"
     ]
    }
   ],
   "source": [
    "def final_model_evaluation(model, test_loader, val_loader, \n",
    "                            model_name, criterion, criterion_unweighted, \n",
    "                            optimizer, train_losses, train_unweighted_losses, \n",
    "                            val_losses, val_unweighted_losses, patience, epoch, start_time):\n",
    "    \"\"\"\n",
    "    Evaluates the LSTM model on the test and validation sets.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained LSTM model to evaluate.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        val_loader (DataLoader): DataLoader for the validation dataset.\n",
    "        test_files (list): List of test files used to create predictions.\n",
    "        model_name (str): Name of the model for saving results.\n",
    "        criterion (nn.Module): Weighted loss function.\n",
    "        criterion_unweighted (nn.Module): Unweighted loss function.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer used in training.\n",
    "        train_losses (list): List of training losses per epoch.\n",
    "        train_unweighted_losses (list): List of unweighted training losses per epoch.\n",
    "        val_losses (list): List of validation losses per epoch.\n",
    "        val_unweighted_losses (list): List of unweighted validation losses per epoch.\n",
    "        patience (int): Patience value for early stopping.\n",
    "        epoch (int): Number of training epochs completed.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    model.eval()  \n",
    "    predictions = []\n",
    "    val_predictions = []\n",
    "    ground_truth = []\n",
    "    val_ground_truth = []\n",
    "    date_of_test_predictions = []\n",
    "    date_of_val_predictions = []\n",
    "    tickers_of_test_predictions = []\n",
    "    tickers_of_val_predictions = []\n",
    "    total_test_loss = 0\n",
    "    total_val_loss = 0\n",
    "    total_unweighted_test_loss = 0\n",
    "    total_unweighted_val_loss = 0\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for X_batch, y_batch, y_batch_dates, y_batch_tickers in test_loader:\n",
    "            date_of_test_predictions.extend(y_batch_dates)\n",
    "            tickers_of_test_predictions.extend(y_batch_tickers)\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            batch_predictions = model(X_batch).squeeze(-1)  \n",
    "            predictions.extend(batch_predictions.cpu().numpy())\n",
    "            ground_truth.extend(y_batch.cpu().numpy())\n",
    "            total_test_loss += criterion(batch_predictions, y_batch.float()).item()\n",
    "            total_unweighted_test_loss += criterion_unweighted(batch_predictions, y_batch.float()).item()\n",
    "\n",
    "\n",
    "        for X_batch, y_batch, y_batch_dates, y_batch_tickers in val_loader:\n",
    "            date_of_val_predictions.extend(y_batch_dates)\n",
    "            tickers_of_val_predictions.extend(y_batch_tickers)\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            val_batch_predictions = model(X_batch).squeeze(-1) \n",
    "            val_predictions.extend(val_batch_predictions.cpu().numpy())\n",
    "            val_ground_truth.extend(y_batch.cpu().numpy())\n",
    "            total_val_loss += criterion(val_batch_predictions, y_batch.float()).item()\n",
    "            total_unweighted_val_loss += criterion_unweighted(val_batch_predictions, y_batch.float()).item()\n",
    "\n",
    "\n",
    "    test_loss = total_test_loss / len(test_loader)\n",
    "    test_unweighted_loss = total_unweighted_test_loss / len(test_loader)\n",
    "    val_loss = total_val_loss / len(val_loader)\n",
    "    val_unweighted_loss = total_unweighted_val_loss / len(val_loader)\n",
    "\n",
    "    # THis is the results dictionary that was fucky on the ATGCN 1,2 and 3\n",
    "    results_dict = {\n",
    "        \"Test_Dates\": date_of_test_predictions,\n",
    "        \"Prediction\": predictions,\n",
    "        \"Ground Truth\": ground_truth,\n",
    "        \"Tickers\": tickers_of_test_predictions,\n",
    "        \"Val_Dates\": date_of_val_predictions,\n",
    "        \"Val_Prediction\": val_predictions,\n",
    "        \"Val_Ground Truth\": val_ground_truth,\n",
    "        \"Val_Tickers\": tickers_of_val_predictions,\n",
    "        \"Model_Name\": model_name,\n",
    "        \"Hidden_Dim\": model.lstm.hidden_size,  \n",
    "        \"Num_Layers\": model.lstm.num_layers,  \n",
    "        \"Batch_Size\": test_loader.batch_size,\n",
    "        \"Optimizer\": optimizer.__class__.__name__,\n",
    "        \"Learning_Rate\": optimizer.param_groups[0]['lr'],\n",
    "        \"Gamme (LR Decay)\": gamma,\n",
    "        \"Loss_Function\": \"WeightedMSELoss\",\n",
    "        \"Loss_Function_Weights\": criterion.weights,\n",
    "        \"Dropout\": drop_out_rate,\n",
    "        \"Epochs\": epoch,\n",
    "        \"Train_Time\": str(time.time() - start_time),\n",
    "        \"Patience\": patience,\n",
    "        \"Train_Loss\": train_losses,\n",
    "        \"Train_Unweighted_Loss\": train_unweighted_losses,\n",
    "        \"Val_Loss\": val_losses,\n",
    "        \"Val_Unweighted_Loss\": val_unweighted_losses,\n",
    "        \"Test_Loss\": test_loss,\n",
    "        \"Test_Unweighted_Loss\": test_unweighted_loss\n",
    "    }\n",
    "\n",
    "    with open(f\"../Data/Results/{model_name}_results.pkl\", 'wb') as f:\n",
    "        pickle.dump(results_dict, f)\n",
    "\n",
    "    print(f\"Results saved to ../Data/Results/{model_name}_results.pkl\")\n",
    "\n",
    "\n",
    "final_model_evaluation(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    val_loader=val_loader,\n",
    "    model_name=model_name,\n",
    "    criterion=criterion,\n",
    "    criterion_unweighted=criterion_unweighted,\n",
    "    optimizer=optimizer,\n",
    "    train_losses=train_losses,\n",
    "    train_unweighted_losses=train_unweighted_losses,\n",
    "    val_losses=val_losses,\n",
    "    val_unweighted_losses=val_unweighted_losses,\n",
    "    patience=patience,\n",
    "    epoch=epoch,\n",
    "    start_time=model_train_start_time\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
